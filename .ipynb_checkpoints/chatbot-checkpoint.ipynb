{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Hiep\n",
      "[nltk_data]     Nguyen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Hiep\n",
      "[nltk_data]     Nguyen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet') \n",
    "from numpy import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Một số định nghĩa cơ bản"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## NLP là gì? \n",
    "NLP bao gồm những kỹ thuật xử lí ngôn ngữ để máy tính có thể hiểu và xử lý được các từ ngữ gần giống như con người\n",
    "\n",
    "Một vài ứng dụng của NLP là: \n",
    "<ul>\n",
    "<li>Chatbot</li>\n",
    "<li>Hệ thống dịch tự động</li>\n",
    "<li>Phân tích cảm xúc ngôn ngữ\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot là gì?\n",
    "\n",
    "Là một ứng dụng của NLP, nôm na là một hệ thống tự động có thể nói chuyện được với con người. \n",
    "Một số dạng chatbot cơ bản bao gồm:\n",
    "<ul>\n",
    "<li>Câu hỏi - trả lời</li>\n",
    "<li>Nói chuyện giống như người thật</li>\n",
    "</ul>\n",
    "\n",
    "Thường thì mỗi chatbot sẽ được xây dựng cho một mục đích nhất định, ví dụ như bán hàng, tiêu khiển,... \n",
    "\n",
    "Rất khó để có thể xây dựng được một chatbot có thể trả lời được nhiều topics và làm được nhiều chức năng cùng một lúc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"meme.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xây dựng chatbot như thế nào?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cách đơn giản nhất là xây theo quy luật (rule-based)\n",
    "\n",
    "ví dụ: nhận input là \"xin chào\" thì bot được lập trình để trả lời lại là \"Tôi có thể giúp gì được cho bạn không?\"\n",
    "\n",
    "## 2. Trả lời theo từ khóa\n",
    "\n",
    "ví dụ: nhận input là \"giá của cái máy tính này là bao nhiêu?\" thì chatbot tìm các câu trả lời có chứa 'máy tính', cũng như 'giá tiền' để đáp lại\n",
    "\n",
    "## 3. Và cuối cùng, loại khó nhất, sử dụng deep learning (thường được các công ty sử dụng)\n",
    "\n",
    "một số kỹ thuật thường dùng để xây chatbot thông minh là sequence-to-sequence model, attention, transformer,..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> CÙNG BẮT ĐẦU THÔI </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"I am attending a hackathon today. Hopefully I will a prize\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'attending',\n",
       " 'a',\n",
       " 'hackathon',\n",
       " 'today',\n",
       " '.',\n",
       " 'Hopefully',\n",
       " 'I',\n",
       " 'will',\n",
       " 'a',\n",
       " 'prize']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am attending a hackathon today.', 'Hopefully I will a prize']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "attending\n"
     ]
    }
   ],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "print(lemmer.lemmatize('runs'))\n",
    "print(lemmer.lemmatize('attending'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tf-idf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine-similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dùng để tính khoảng cách giữa 2 véc-tơ trong không gian\n",
    "<img src=\"cosine-similarity.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Chatbot DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.txt','r',errors = 'ignore') as f:\n",
    "    raw = f.read()\n",
    "raw=raw.lower()# converts to lowercase\n",
    "raw = re.sub(r'\\[\\d+\\]', '', raw) # remove citation format\n",
    "\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "def remove_punc(text):\n",
    "    return text.lower().translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(remove_punc(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'ai',\n",
       " 'sometimes',\n",
       " 'called',\n",
       " 'machine',\n",
       " 'intelligence',\n",
       " 'is',\n",
       " 'intelligence',\n",
       " 'demonstrated',\n",
       " 'by',\n",
       " 'machine',\n",
       " 'unlike',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'displayed',\n",
       " 'by',\n",
       " 'human',\n",
       " 'and',\n",
       " 'animal',\n",
       " 'leading',\n",
       " 'ai',\n",
       " 'textbook',\n",
       " 'define',\n",
       " 'the',\n",
       " 'field',\n",
       " 'a',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " 'intelligent',\n",
       " 'agent',\n",
       " 'any',\n",
       " 'device',\n",
       " 'that',\n",
       " 'perceives',\n",
       " 'it',\n",
       " 'environment',\n",
       " 'and',\n",
       " 'take',\n",
       " 'action',\n",
       " 'that',\n",
       " 'maximize',\n",
       " 'it',\n",
       " 'chance',\n",
       " 'of',\n",
       " 'successfully',\n",
       " 'achieving',\n",
       " 'it',\n",
       " 'goal',\n",
       " 'colloquially',\n",
       " 'the',\n",
       " 'term',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'is',\n",
       " 'often',\n",
       " 'used',\n",
       " 'to',\n",
       " 'describe',\n",
       " 'machine',\n",
       " 'or',\n",
       " 'computer',\n",
       " 'that',\n",
       " 'mimic',\n",
       " 'cognitive',\n",
       " 'function',\n",
       " 'that',\n",
       " 'human',\n",
       " 'associate',\n",
       " 'with',\n",
       " 'the',\n",
       " 'human',\n",
       " 'mind',\n",
       " 'such',\n",
       " 'a',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'problem',\n",
       " 'solving',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'become',\n",
       " 'increasingly',\n",
       " 'capable',\n",
       " 'task',\n",
       " 'considered',\n",
       " 'to',\n",
       " 'require',\n",
       " 'intelligence',\n",
       " 'are',\n",
       " 'often',\n",
       " 'removed',\n",
       " 'from',\n",
       " 'the',\n",
       " 'definition',\n",
       " 'of',\n",
       " 'ai',\n",
       " 'a',\n",
       " 'phenomenon',\n",
       " 'known',\n",
       " 'a',\n",
       " 'the',\n",
       " 'ai',\n",
       " 'effect',\n",
       " 'a',\n",
       " 'quip',\n",
       " 'in',\n",
       " 'teslers',\n",
       " 'theorem',\n",
       " 'say',\n",
       " 'ai',\n",
       " 'is',\n",
       " 'whatever',\n",
       " 'hasnt',\n",
       " 'been',\n",
       " 'done',\n",
       " 'yet',\n",
       " 'for',\n",
       " 'instance',\n",
       " 'optical',\n",
       " 'character',\n",
       " 'recognition',\n",
       " 'is',\n",
       " 'frequently',\n",
       " 'excluded',\n",
       " 'from',\n",
       " 'thing',\n",
       " 'considered',\n",
       " 'to',\n",
       " 'be',\n",
       " 'ai',\n",
       " 'having',\n",
       " 'become',\n",
       " 'a',\n",
       " 'routine',\n",
       " 'technology',\n",
       " 'modern',\n",
       " 'machine',\n",
       " 'capability',\n",
       " 'generally',\n",
       " 'classified',\n",
       " 'a',\n",
       " 'ai',\n",
       " 'include',\n",
       " 'successfully',\n",
       " 'understanding',\n",
       " 'human',\n",
       " 'speech',\n",
       " 'competing',\n",
       " 'at',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'level',\n",
       " 'in',\n",
       " 'strategic',\n",
       " 'game',\n",
       " 'system',\n",
       " 'such',\n",
       " 'a',\n",
       " 'chess',\n",
       " 'and',\n",
       " 'go',\n",
       " 'autonomously',\n",
       " 'operating',\n",
       " 'car',\n",
       " 'intelligent',\n",
       " 'routing',\n",
       " 'in',\n",
       " 'content',\n",
       " 'delivery',\n",
       " 'network',\n",
       " 'and',\n",
       " 'military',\n",
       " 'simulation',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'wa',\n",
       " 'founded',\n",
       " 'a',\n",
       " 'an',\n",
       " 'academic',\n",
       " 'discipline',\n",
       " 'in',\n",
       " '1955',\n",
       " 'and',\n",
       " 'in',\n",
       " 'the',\n",
       " 'year',\n",
       " 'since',\n",
       " 'ha',\n",
       " 'experienced',\n",
       " 'several',\n",
       " 'wave',\n",
       " 'of',\n",
       " 'optimism',\n",
       " 'followed',\n",
       " 'by',\n",
       " 'disappointment',\n",
       " 'and',\n",
       " 'the',\n",
       " 'loss',\n",
       " 'of',\n",
       " 'funding',\n",
       " 'known',\n",
       " 'a',\n",
       " 'an',\n",
       " 'ai',\n",
       " 'winter',\n",
       " 'followed',\n",
       " 'by',\n",
       " 'new',\n",
       " 'approach',\n",
       " 'success',\n",
       " 'and',\n",
       " 'renewed',\n",
       " 'funding',\n",
       " 'for',\n",
       " 'most',\n",
       " 'of',\n",
       " 'it',\n",
       " 'history',\n",
       " 'ai',\n",
       " 'research',\n",
       " 'ha',\n",
       " 'been',\n",
       " 'divided',\n",
       " 'into',\n",
       " 'subfields',\n",
       " 'that',\n",
       " 'often',\n",
       " 'fail',\n",
       " 'to',\n",
       " 'communicate',\n",
       " 'with',\n",
       " 'each',\n",
       " 'other',\n",
       " 'these',\n",
       " 'subfields',\n",
       " 'are',\n",
       " 'based',\n",
       " 'on',\n",
       " 'technical',\n",
       " 'consideration',\n",
       " 'such',\n",
       " 'a',\n",
       " 'particular',\n",
       " 'goal',\n",
       " 'eg',\n",
       " 'robotics',\n",
       " 'or',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'particular',\n",
       " 'tool',\n",
       " 'logic',\n",
       " 'or',\n",
       " 'artificial',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'or',\n",
       " 'deep',\n",
       " 'philosophical',\n",
       " 'difference',\n",
       " 'subfields',\n",
       " 'have',\n",
       " 'also',\n",
       " 'been',\n",
       " 'based',\n",
       " 'on',\n",
       " 'social',\n",
       " 'factor',\n",
       " 'particular',\n",
       " 'institution',\n",
       " 'or',\n",
       " 'the',\n",
       " 'work',\n",
       " 'of',\n",
       " 'particular',\n",
       " 'researcher',\n",
       " 'the',\n",
       " 'traditional',\n",
       " 'problem',\n",
       " 'or',\n",
       " 'goal',\n",
       " 'of',\n",
       " 'ai',\n",
       " 'research',\n",
       " 'include',\n",
       " 'reasoning',\n",
       " 'knowledge',\n",
       " 'representation',\n",
       " 'planning',\n",
       " 'learning',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'perception',\n",
       " 'and',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'move',\n",
       " 'and',\n",
       " 'manipulate',\n",
       " 'object',\n",
       " 'general',\n",
       " 'intelligence',\n",
       " 'is',\n",
       " 'among',\n",
       " 'the',\n",
       " 'field',\n",
       " 'longterm',\n",
       " 'goal',\n",
       " 'approach',\n",
       " 'include',\n",
       " 'statistical',\n",
       " 'method',\n",
       " 'computational',\n",
       " 'intelligence',\n",
       " 'and',\n",
       " 'traditional',\n",
       " 'symbolic',\n",
       " 'ai',\n",
       " 'many',\n",
       " 'tool',\n",
       " 'are',\n",
       " 'used',\n",
       " 'in',\n",
       " 'ai',\n",
       " 'including',\n",
       " 'version',\n",
       " 'of',\n",
       " 'search',\n",
       " 'and',\n",
       " 'mathematical',\n",
       " 'optimization',\n",
       " 'artificial',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'and',\n",
       " 'method',\n",
       " 'based',\n",
       " 'on',\n",
       " 'statistic',\n",
       " 'probability',\n",
       " 'and',\n",
       " 'economics',\n",
       " 'the',\n",
       " 'ai',\n",
       " 'field',\n",
       " 'draw',\n",
       " 'upon',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'information',\n",
       " 'engineering',\n",
       " 'mathematics',\n",
       " 'psychology',\n",
       " 'linguistics',\n",
       " 'philosophy',\n",
       " 'and',\n",
       " 'many',\n",
       " 'other',\n",
       " 'field',\n",
       " 'the',\n",
       " 'field',\n",
       " 'wa',\n",
       " 'founded',\n",
       " 'on',\n",
       " 'the',\n",
       " 'assumption',\n",
       " 'that',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'can',\n",
       " 'be',\n",
       " 'so',\n",
       " 'precisely',\n",
       " 'described',\n",
       " 'that',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'can',\n",
       " 'be',\n",
       " 'made',\n",
       " 'to',\n",
       " 'simulate',\n",
       " 'it',\n",
       " 'this',\n",
       " 'raise',\n",
       " 'philosophical',\n",
       " 'argument',\n",
       " 'about',\n",
       " 'the',\n",
       " 'mind',\n",
       " 'and',\n",
       " 'the',\n",
       " 'ethic',\n",
       " 'of',\n",
       " 'creating',\n",
       " 'artificial',\n",
       " 'being',\n",
       " 'endowed',\n",
       " 'with',\n",
       " 'humanlike',\n",
       " 'intelligence',\n",
       " 'these',\n",
       " 'issue',\n",
       " 'have',\n",
       " 'been',\n",
       " 'explored',\n",
       " 'by',\n",
       " 'myth',\n",
       " 'fiction',\n",
       " 'and',\n",
       " 'philosophy',\n",
       " 'since',\n",
       " 'antiquity',\n",
       " 'some',\n",
       " 'people',\n",
       " 'also',\n",
       " 'consider',\n",
       " 'ai',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'danger',\n",
       " 'to',\n",
       " 'humanity',\n",
       " 'if',\n",
       " 'it',\n",
       " 'progress',\n",
       " 'unabated',\n",
       " 'others',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'ai',\n",
       " 'unlike',\n",
       " 'previous',\n",
       " 'technological',\n",
       " 'revolution',\n",
       " 'will',\n",
       " 'create',\n",
       " 'a',\n",
       " 'risk',\n",
       " 'of',\n",
       " 'mass',\n",
       " 'unemployment',\n",
       " 'in',\n",
       " 'the',\n",
       " 'twentyfirst',\n",
       " 'century',\n",
       " 'ai',\n",
       " 'technique',\n",
       " 'have',\n",
       " 'experienced',\n",
       " 'a',\n",
       " 'resurgence',\n",
       " 'following',\n",
       " 'concurrent',\n",
       " 'advance',\n",
       " 'in',\n",
       " 'computer',\n",
       " 'power',\n",
       " 'large',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'data',\n",
       " 'and',\n",
       " 'theoretical',\n",
       " 'understanding',\n",
       " 'and',\n",
       " 'ai',\n",
       " 'technique',\n",
       " 'have',\n",
       " 'become',\n",
       " 'an',\n",
       " 'essential',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'technology',\n",
       " 'industry',\n",
       " 'helping',\n",
       " 'to',\n",
       " 'solve',\n",
       " 'many',\n",
       " 'challenging',\n",
       " 'problem',\n",
       " 'in',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'software',\n",
       " 'engineering',\n",
       " 'and',\n",
       " 'operation',\n",
       " 'research',\n",
       " 'thoughtcapable',\n",
       " 'artificial',\n",
       " 'being',\n",
       " 'appeared',\n",
       " 'a',\n",
       " 'storytelling',\n",
       " 'device',\n",
       " 'in',\n",
       " 'antiquity',\n",
       " 'and',\n",
       " 'have',\n",
       " 'been',\n",
       " 'common',\n",
       " 'in',\n",
       " 'fiction',\n",
       " 'a',\n",
       " 'in',\n",
       " 'mary',\n",
       " 'shelley',\n",
       " 'frankenstein',\n",
       " 'or',\n",
       " 'karel',\n",
       " 'äœapeks',\n",
       " 'rur',\n",
       " 'these',\n",
       " 'character',\n",
       " 'and',\n",
       " 'their',\n",
       " 'fate',\n",
       " 'raised',\n",
       " 'many',\n",
       " 'of',\n",
       " 'the',\n",
       " 'same',\n",
       " 'issue',\n",
       " 'now',\n",
       " 'discussed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'ethic',\n",
       " 'of',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " 'mechanical',\n",
       " 'or',\n",
       " 'formal',\n",
       " 'reasoning',\n",
       " 'began',\n",
       " 'with',\n",
       " 'philosopher',\n",
       " 'and',\n",
       " 'mathematician',\n",
       " 'in',\n",
       " 'antiquity',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " 'mathematical',\n",
       " 'logic',\n",
       " 'led',\n",
       " 'directly',\n",
       " 'to',\n",
       " 'alan',\n",
       " 'turing',\n",
       " 'theory',\n",
       " 'of',\n",
       " 'computation',\n",
       " 'which',\n",
       " 'suggested',\n",
       " 'that',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'by',\n",
       " 'shuffling',\n",
       " 'symbol',\n",
       " 'a',\n",
       " 'simple',\n",
       " 'a',\n",
       " '0',\n",
       " 'and',\n",
       " '1',\n",
       " 'could',\n",
       " 'simulate',\n",
       " 'any',\n",
       " 'conceivable',\n",
       " 'act',\n",
       " 'of',\n",
       " 'mathematical',\n",
       " 'deduction',\n",
       " 'this',\n",
       " 'insight',\n",
       " 'that',\n",
       " 'digital',\n",
       " 'computer',\n",
       " 'can',\n",
       " 'simulate',\n",
       " 'any',\n",
       " 'process',\n",
       " 'of',\n",
       " 'formal',\n",
       " 'reasoning',\n",
       " 'is',\n",
       " 'known',\n",
       " 'a',\n",
       " 'the',\n",
       " 'churchâ€',\n",
       " '“',\n",
       " 'turing',\n",
       " 'thesis',\n",
       " 'along',\n",
       " 'with',\n",
       " 'concurrent',\n",
       " 'discovery',\n",
       " 'in',\n",
       " 'neurobiology',\n",
       " 'information',\n",
       " 'theory',\n",
       " 'and',\n",
       " 'cybernetics',\n",
       " 'this',\n",
       " 'led',\n",
       " 'researcher',\n",
       " 'to',\n",
       " 'consider',\n",
       " 'the',\n",
       " 'possibility',\n",
       " 'of',\n",
       " 'building',\n",
       " 'an',\n",
       " 'electronic',\n",
       " 'brain',\n",
       " 'turing',\n",
       " 'proposed',\n",
       " 'changing',\n",
       " 'the',\n",
       " 'question',\n",
       " 'from',\n",
       " 'whether',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'wa',\n",
       " 'intelligent',\n",
       " 'to',\n",
       " 'whether',\n",
       " 'or',\n",
       " 'not',\n",
       " 'it',\n",
       " 'is',\n",
       " 'possible',\n",
       " 'for',\n",
       " 'machinery',\n",
       " 'to',\n",
       " 'show',\n",
       " 'intelligent',\n",
       " 'behaviour',\n",
       " 'the',\n",
       " 'first',\n",
       " 'work',\n",
       " 'that',\n",
       " 'is',\n",
       " 'now',\n",
       " 'generally',\n",
       " 'recognized',\n",
       " 'a',\n",
       " 'ai',\n",
       " 'wa',\n",
       " 'mccullouch',\n",
       " 'and',\n",
       " 'pitt',\n",
       " '1943',\n",
       " 'formal',\n",
       " 'design',\n",
       " 'for',\n",
       " 'turingcomplete',\n",
       " 'artificial',\n",
       " 'neuron',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'ai',\n",
       " 'research',\n",
       " 'wa',\n",
       " 'born',\n",
       " 'at',\n",
       " 'a',\n",
       " 'workshop',\n",
       " 'at',\n",
       " 'dartmouth',\n",
       " 'college',\n",
       " 'in',\n",
       " '1956',\n",
       " 'where',\n",
       " 'the',\n",
       " 'term',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'wa',\n",
       " 'coined',\n",
       " 'by',\n",
       " 'john',\n",
       " 'mccarthy',\n",
       " 'to',\n",
       " 'distinguish',\n",
       " 'the',\n",
       " 'field',\n",
       " 'from',\n",
       " 'cybernetics',\n",
       " 'and',\n",
       " 'escape',\n",
       " 'the',\n",
       " 'influence',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cyberneticist',\n",
       " 'norbert',\n",
       " 'wiener',\n",
       " 'attendee',\n",
       " 'allen',\n",
       " 'newell',\n",
       " 'cmu',\n",
       " 'herbert',\n",
       " 'simon',\n",
       " 'cmu',\n",
       " 'john',\n",
       " 'mccarthy',\n",
       " 'mit',\n",
       " 'marvin',\n",
       " 'minsky',\n",
       " 'mit',\n",
       " 'and',\n",
       " 'arthur',\n",
       " 'samuel',\n",
       " 'ibm',\n",
       " 'became',\n",
       " 'the',\n",
       " 'founder',\n",
       " 'and',\n",
       " 'leader',\n",
       " 'of',\n",
       " 'ai',\n",
       " 'research',\n",
       " 'they',\n",
       " 'and',\n",
       " 'their',\n",
       " 'student',\n",
       " 'produced',\n",
       " 'program',\n",
       " 'that',\n",
       " 'the',\n",
       " 'press',\n",
       " 'described',\n",
       " 'a',\n",
       " 'astonishing',\n",
       " 'computer',\n",
       " 'were',\n",
       " 'learning',\n",
       " 'checker',\n",
       " 'strategy',\n",
       " 'c',\n",
       " '1954',\n",
       " 'and',\n",
       " 'by',\n",
       " '1959',\n",
       " 'were',\n",
       " 'reportedly',\n",
       " 'playing',\n",
       " 'better',\n",
       " 'than',\n",
       " 'the',\n",
       " 'average',\n",
       " 'human',\n",
       " 'solving',\n",
       " 'word',\n",
       " 'problem',\n",
       " 'in',\n",
       " 'algebra',\n",
       " 'proving',\n",
       " 'logical',\n",
       " 'theorem',\n",
       " 'logic',\n",
       " 'theorist',\n",
       " 'first',\n",
       " 'run',\n",
       " 'c',\n",
       " '1956',\n",
       " 'and',\n",
       " 'speaking',\n",
       " 'english',\n",
       " 'by',\n",
       " 'the',\n",
       " 'middle',\n",
       " 'of',\n",
       " 'the',\n",
       " '1960s',\n",
       " 'research',\n",
       " 'in',\n",
       " 'the',\n",
       " 'u',\n",
       " 'wa',\n",
       " 'heavily',\n",
       " 'funded',\n",
       " 'by',\n",
       " 'the',\n",
       " 'department',\n",
       " 'of',\n",
       " 'defense',\n",
       " 'and',\n",
       " 'laboratory',\n",
       " 'had',\n",
       " 'been',\n",
       " 'established',\n",
       " 'around',\n",
       " 'the',\n",
       " 'world',\n",
       " 'ai',\n",
       " 'founder',\n",
       " 'were',\n",
       " 'optimistic',\n",
       " 'about',\n",
       " 'the',\n",
       " 'future',\n",
       " 'herbert',\n",
       " 'simon',\n",
       " 'predicted',\n",
       " 'machine',\n",
       " 'will',\n",
       " 'be',\n",
       " 'capable',\n",
       " 'within',\n",
       " 'twenty',\n",
       " 'year',\n",
       " 'of',\n",
       " 'doing',\n",
       " 'any',\n",
       " 'work',\n",
       " 'a',\n",
       " 'man',\n",
       " 'can',\n",
       " 'do',\n",
       " 'marvin',\n",
       " 'minsky',\n",
       " 'agreed',\n",
       " 'writing',\n",
       " 'within',\n",
       " 'a',\n",
       " 'generation',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'of',\n",
       " 'creating',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'will',\n",
       " 'substantially',\n",
       " 'be',\n",
       " 'solved',\n",
       " 'they',\n",
       " 'failed',\n",
       " 'to',\n",
       " 'recognize',\n",
       " 'the',\n",
       " 'difficulty',\n",
       " 'of',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'remaining',\n",
       " 'task',\n",
       " 'progress',\n",
       " 'slowed',\n",
       " 'and',\n",
       " 'in',\n",
       " '1974',\n",
       " 'in',\n",
       " 'response',\n",
       " 'to',\n",
       " 'the',\n",
       " 'criticism',\n",
       " 'of',\n",
       " 'sir',\n",
       " 'james',\n",
       " 'lighthill',\n",
       " 'and',\n",
       " 'ongoing',\n",
       " 'pressure',\n",
       " 'from',\n",
       " 'the',\n",
       " 'u',\n",
       " 'congress',\n",
       " 'to',\n",
       " 'fund',\n",
       " 'more',\n",
       " 'productive',\n",
       " 'project',\n",
       " 'both',\n",
       " 'the',\n",
       " 'u',\n",
       " 'and',\n",
       " 'british',\n",
       " 'government',\n",
       " 'cut',\n",
       " 'off',\n",
       " 'exploratory',\n",
       " 'research',\n",
       " 'in',\n",
       " 'ai',\n",
       " 'the',\n",
       " 'next',\n",
       " 'few',\n",
       " 'year',\n",
       " 'would',\n",
       " 'later',\n",
       " 'be',\n",
       " 'called',\n",
       " 'an',\n",
       " 'ai',\n",
       " 'winter',\n",
       " 'a',\n",
       " 'period',\n",
       " 'when',\n",
       " 'obtaining',\n",
       " 'funding',\n",
       " 'for',\n",
       " 'ai',\n",
       " 'project',\n",
       " 'wa',\n",
       " 'difficult',\n",
       " 'in',\n",
       " 'the',\n",
       " 'early',\n",
       " '1980s',\n",
       " 'ai',\n",
       " 'research',\n",
       " 'wa',\n",
       " 'revived',\n",
       " 'by',\n",
       " 'the',\n",
       " 'commercial',\n",
       " 'success',\n",
       " 'of',\n",
       " 'expert',\n",
       " 'system',\n",
       " 'a',\n",
       " 'form',\n",
       " 'of',\n",
       " 'ai',\n",
       " 'program',\n",
       " 'that',\n",
       " 'simulated',\n",
       " 'the',\n",
       " 'knowledge',\n",
       " 'and',\n",
       " 'analytical',\n",
       " 'skill',\n",
       " 'of',\n",
       " 'human',\n",
       " 'expert',\n",
       " 'by',\n",
       " '1985',\n",
       " 'the',\n",
       " 'market',\n",
       " 'for',\n",
       " 'ai',\n",
       " 'had',\n",
       " 'reached',\n",
       " 'over',\n",
       " 'a',\n",
       " 'billion',\n",
       " 'dollar',\n",
       " 'at',\n",
       " 'the',\n",
       " 'same',\n",
       " 'time',\n",
       " 'japan',\n",
       " 'fifth',\n",
       " 'generation',\n",
       " 'computer',\n",
       " 'project',\n",
       " 'inspired',\n",
       " 'the',\n",
       " 'u',\n",
       " 'and',\n",
       " 'british',\n",
       " 'government',\n",
       " 'to',\n",
       " 'restore',\n",
       " 'funding',\n",
       " 'for',\n",
       " 'academic',\n",
       " 'research',\n",
       " 'however',\n",
       " 'beginning',\n",
       " ...]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LemNormalize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = [\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\"]\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"hi there\", \"hello\", \"how can i help you?\"]\n",
    "def greeting(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_chat):\n",
    "\n",
    "    sent_tokens.append(user_chat)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2] #get the index of sentence with highest similarity score\n",
    "    flat = vals.reshape(-1)\n",
    "    flat.sort()\n",
    "    input_tfidf = flat[-2] #get the tf-idf score of output sentence\n",
    "    if input_tfidf==0:\n",
    "        bot_response= \"I am sorry! I have never heard about the things you just said\"\n",
    "        return bot_response\n",
    "    else:\n",
    "        bot_response = sent_tokens[idx]\n",
    "        sent_tokens.pop()\n",
    "        return bot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob: Hello, My name is Bob and I am a robot. How can I answer your questions today?\n",
      "bye\n",
      "Bob: Bye! hope to see you soon!\n"
     ]
    }
   ],
   "source": [
    "give_answer =True\n",
    "print(\"Bob: Hello, My name is Bob and I am a robot. How can I answer your questions today?\")\n",
    "while give_answer:\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if user_response!='bye':\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            print(\"Bob: You are welcome. Is there something else you need help with?\")\n",
    "        else:\n",
    "            if greeting(user_response):\n",
    "                print(\"Bob: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"Bob: \"+response(user_response))\n",
    "    else:\n",
    "        print(\"Bob: Bye! hope to see you soon!\")\n",
    "        give_answer=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"w2v.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vectors(glove_file):\n",
    "    with open(glove_file,'r', encoding=\"utf8\") as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "\n",
    "    return word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = read_glove_vectors('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.0334e-01,  1.0577e+00, -3.0452e-01,  5.6728e-02,  6.2269e-04,\n",
       "       -1.5874e-01, -3.9343e-01, -1.6816e+00,  2.5751e-01,  9.6477e-02,\n",
       "        2.2256e-01,  4.0022e-01, -1.3319e-01,  5.0095e-01, -3.1653e-01,\n",
       "       -1.3437e-01,  3.6205e-01,  1.1403e+00, -4.6058e-01,  7.8453e-01,\n",
       "        1.1051e+00,  6.7427e-01,  3.3348e-01, -1.9985e-01,  8.8040e-01,\n",
       "       -1.5153e+00, -1.0876e+00, -9.7803e-01, -1.0249e+00, -8.1350e-02,\n",
       "        2.6487e+00, -4.7125e-01, -4.5275e-01, -2.0287e+00, -4.0910e-01,\n",
       "        2.6637e-01, -6.6804e-01,  1.1231e+00,  8.9049e-01,  2.0298e-01,\n",
       "       -2.4961e-02, -4.6865e-01,  2.5623e-01,  3.7514e-01, -1.2434e-01,\n",
       "        7.2878e-01,  9.0596e-01,  8.3551e-01,  2.2837e-04,  4.4761e-01])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v['science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_vector(corpus):\n",
    "    out = []\n",
    "    for sentence in corpus:\n",
    "        sentence_score = 0\n",
    "\n",
    "        for word in sentence.split():\n",
    "            word = remove_punc(word)\n",
    "            if word in w2v:\n",
    "                word_vec = w2v[word]\n",
    "            else:\n",
    "                word_vec = w2v['unk']\n",
    "            sentence_score+=word_vec\n",
    "        out.append(sentence_score/len(sentence.split()))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding = get_average_vector(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_w2v(user_chat):\n",
    "    user_chat = user_chat.lower()\n",
    "    input_score = 0\n",
    "    similar_score = []\n",
    "    for word in user_chat.split():\n",
    "        word = remove_punc(word)\n",
    "        if word in w2v:\n",
    "            word_vec = w2v[word]\n",
    "        else:\n",
    "            word_vec = w2v['unk']\n",
    "        input_score +=word_vec\n",
    "    input_score = input_score / (len(user_chat.split()))\n",
    "    for i in range(len(sentence_embedding)):\n",
    "        sentence_in_corpus = sentence_embedding[i].reshape(1,50)\n",
    "        input_vector = input_score.reshape(1,50)\n",
    "        similar_score.append(cosine_similarity(sentence_in_corpus,input_vector).reshape(-1))\n",
    "#         similar_score.append(linalg.norm(sentence_in_corpus-input_vector))\n",
    "    idx= np.argmax(np.array(similar_score))\n",
    "\n",
    "    return sent_tokens[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob: Hello, My name is Bob and I am a robot. How can I answer your questions today?\n",
      "what is ai\n",
      "Bob: a quip in tesler's theorem says \"ai is whatever hasn't been done yet.\"\n",
      "what is nlp\n",
      "Bob: beyond semantic nlp, the ultimate goal of \"narrative\" nlp is to embody a full understanding of commonsense reasoning.\n",
      "what is machine learning\n",
      "Bob: this insight, that digital computers can simulate any process of formal reasoning, is known as the churchâ€“turing thesis.\n",
      "bye\n",
      "Bob: Bye! hope to see you soon!\n"
     ]
    }
   ],
   "source": [
    "give_answer =True\n",
    "print(\"Bob: Hello, My name is Bob and I am a robot. How can I answer your questions today?\")\n",
    "while give_answer:\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if user_response!='bye':\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            print(\"Bob: You are welcome. Is there something else you need help with?\")\n",
    "        else:\n",
    "            if greeting(user_response):\n",
    "                print(\"Bob: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"Bob: \"+get_response_w2v(user_response))\n",
    "    else:\n",
    "        print(\"Bob: Bye! hope to see you soon!\")\n",
    "        give_answer=False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
